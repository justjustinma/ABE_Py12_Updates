{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABE tutorial 6\n",
    "## Adapting our agent for continuous learning in dynamic environments\n",
    "\n",
    "In this fifth tutorial let's prepare our agent to learn continuously in dynamic environments where the sequence of events is important. We'll learn how to facilitate learning through the use of short term memory, and how to observe the environment in a way that keeps the sequence of observations.   \n",
    "\n",
    "Steps:\n",
    "* Add in Generalized Advantage Estimation (memory!)\n",
    "* Add in a replay buffer (memory!)\n",
    "* Add in recurrent network structures (memory!)\n",
    "* Try an environment with continual learning rather than hard resets\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
